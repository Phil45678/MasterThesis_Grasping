{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "004077a9",
   "metadata": {},
   "source": [
    "# Testing codes for loading and equalizing the YCB data set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d495036d",
   "metadata": {},
   "source": [
    "Hyper-paramters and packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "910205fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "\n",
    "nb_classes = 16\n",
    "rand_seed = 42\n",
    "one_hot = True\n",
    "test_train_ratio = 0.2\n",
    "verbose = 2\n",
    "seq_len = 5\n",
    "nb_samples = 100000\n",
    "joint_dist_lim = 0.005\n",
    "nb_tot_samp_class = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e79d5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set location \n",
    "data_set_loc_str = r\"C:\\Users\\phili\\Documents\\GitHub\\DexterousManipulation\\generations\\DATA_SET_YCB_filtered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca5f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os \n",
    "import tensorflow as tf \n",
    "import time \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c79a9d3",
   "metadata": {},
   "source": [
    "Functions from previous codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d28ec80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_non_zero_grasps(data_set_loc_str, nb_samples, nb_classes, lim):\n",
    "\n",
    "    x_min = -0.15\n",
    "    x_max = 0.15\n",
    "    y_min = -0.15\n",
    "    y_max = 0.15 \n",
    "    z_min = 0.13\n",
    "    z_max = 0.35\n",
    "    gripper_min = 0 \n",
    "    gripper_max = 0.041664\n",
    "     \n",
    "    non_zero_metrics_list = [] \n",
    "    non_zero_hands_list = [] \n",
    "    for index in range(nb_classes):\n",
    "        non_zero_metrics_list.append([])\n",
    "        non_zero_hands_list.append([])\n",
    "        \n",
    "    for filename in os.listdir(data_set_loc_str): \n",
    "        file_data = np.load(data_set_loc_str + \"/\" + filename)\n",
    "        \n",
    "        file_metrics = file_data[\"metric\"].astype(np.float64)\n",
    "        file_hand_info = file_data[\"hand\"].astype(np.float64)\n",
    "        file_obj_classes = file_data[\"obj\"].astype(np.float64)\n",
    "        \n",
    "        for metric_index in range(len(file_metrics)):\n",
    "            if file_metrics[metric_index, 0] == 1.0 and file_metrics[metric_index,1] > lim:\n",
    "                curr_class = int(file_obj_classes[metric_index,0])\n",
    "                \n",
    "                non_zero_metrics_list[curr_class].append((file_metrics[metric_index,1] - gripper_min) / (gripper_max - gripper_min))\n",
    "                tmp_hand_info = file_hand_info[metric_index]\n",
    "                tmp_hand_info[0] = (tmp_hand_info[0] - x_min) / (x_max - x_min)\n",
    "                tmp_hand_info[1] = (tmp_hand_info[1] - y_min) / (y_max - y_min)\n",
    "                tmp_hand_info[2] = (tmp_hand_info[2] - z_min) / (z_max - z_min)\n",
    "                \n",
    "                non_zero_hands_list[curr_class].append(tmp_hand_info)\n",
    "                \n",
    "    return non_zero_metrics_list, non_zero_hands_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaefd18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_non_zero_seq(data_set_loc_str, nb_samples, test_train_ratio, rand_seed, verbose, seq_len, nb_classes, lim):\n",
    "    if verbose >= 1:\n",
    "        print(\"Loading Data.\")\n",
    "    start_time = time.time()\n",
    "    non_zero_metrics_list, non_zero_hands_list = load_non_zero_grasps(data_set_loc_str, nb_samples, nb_classes, lim)\n",
    "    end_time = time.time()\n",
    "    if verbose >= 1:\n",
    "        print(\"Time taken to load data: \", end_time - start_time)\n",
    "        \n",
    "    inputs = [] \n",
    "    outputs = []\n",
    "    \n",
    "    # Parsing all buckets \n",
    "    for bucket_index in range(nb_classes):\n",
    "        bucket_offset = 0 \n",
    "        while (bucket_offset + seq_len - 1  < len(non_zero_metrics_list[bucket_index])):\n",
    "            # Build the sequence \n",
    "            tmp_buffer = [] \n",
    "            for seq_index in range(seq_len): \n",
    "                # Fusing the data \n",
    "                tmp_list = [] \n",
    "                tmp_list.append(non_zero_metrics_list[bucket_index][bucket_offset + seq_index])\n",
    "                for hand_index in range(13): \n",
    "                    tmp_list.append(non_zero_hands_list[bucket_index][bucket_offset + seq_index][hand_index])\n",
    "                tmp_buffer.append(tmp_list.copy())\n",
    "            \n",
    "            inputs.append(tmp_buffer.copy())\n",
    "            outputs.append(tf.one_hot(bucket_index, nb_classes, dtype=np.float64).numpy().tolist())\n",
    "            bucket_offset += seq_len \n",
    "            \n",
    "        \n",
    "    # Shuffling the data \n",
    "    X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=test_train_ratio, random_state=rand_seed)\n",
    "    \n",
    "    if verbose >= 1:\n",
    "        print(\"Size of Train set: \", len(X_train))\n",
    "        print(\"Size of Test set: \", len(X_test))\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e68869",
   "metadata": {},
   "source": [
    "New functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fd6afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_non_zero_fused_grasps(data_set_loc_str, nb_classes, lim):\n",
    "\n",
    "    x_min = -0.15\n",
    "    x_max = 0.15\n",
    "    y_min = -0.15\n",
    "    y_max = 0.15 \n",
    "    z_min = 0.13\n",
    "    z_max = 0.35\n",
    "    gripper_min = 0 \n",
    "    gripper_max = 0.041664\n",
    "     \n",
    "    non_zero_grasps_list = []\n",
    "    for index in range(nb_classes):\n",
    "        non_zero_grasps_list.append([])\n",
    "        \n",
    "    for filename in os.listdir(data_set_loc_str): \n",
    "        file_data = np.load(data_set_loc_str + \"/\" + filename)\n",
    "        \n",
    "        file_metrics = file_data[\"metric\"].astype(np.float64)\n",
    "        file_hand_info = file_data[\"hand\"].astype(np.float64)\n",
    "        file_obj_classes = file_data[\"obj\"].astype(np.float64)\n",
    "        \n",
    "        for metric_index in range(len(file_metrics)):\n",
    "            if file_metrics[metric_index, 0] == 1.0 and file_metrics[metric_index,1] > lim:\n",
    "                curr_class = int(file_obj_classes[metric_index,0])\n",
    "                tmp_list = [] \n",
    "                \n",
    "                tmp_list.append((file_metrics[metric_index,1] - gripper_min) / (gripper_max - gripper_min))\n",
    "                tmp_hand_info = file_hand_info[metric_index]\n",
    "                tmp_hand_info[0] = (tmp_hand_info[0] - x_min) / (x_max - x_min)\n",
    "                tmp_hand_info[1] = (tmp_hand_info[1] - y_min) / (y_max - y_min)\n",
    "                tmp_hand_info[2] = (tmp_hand_info[2] - z_min) / (z_max - z_min)\n",
    "                \n",
    "                for tmp_index in range(13): \n",
    "                    tmp_list.append(tmp_hand_info[tmp_index])\n",
    "                \n",
    "                non_zero_grasps_list[curr_class].append(tmp_list.copy())\n",
    "                \n",
    "    return non_zero_grasps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5175d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zero_fused_grasps_buckets(data_set_loc_str, nb_classes, lim, nb_tot_samp_class): \n",
    "    x_min = -0.15\n",
    "    x_max = 0.15\n",
    "    y_min = -0.15\n",
    "    y_max = 0.15 \n",
    "    z_min = 0.13\n",
    "    z_max = 0.35\n",
    "    gripper_min = 0 \n",
    "    gripper_max = 0.041664\n",
    "     \n",
    "    zero_grasps_list = []\n",
    "    for index in range(nb_classes):\n",
    "        zero_grasps_list.append([])\n",
    "        \n",
    "    for filename in os.listdir(data_set_loc_str): \n",
    "        file_data = np.load(data_set_loc_str + \"/\" + filename)\n",
    "        \n",
    "        file_metrics = file_data[\"metric\"].astype(np.float64)\n",
    "        file_hand_info = file_data[\"hand\"].astype(np.float64)\n",
    "        file_obj_classes = file_data[\"obj\"].astype(np.float64)\n",
    "        \n",
    "        counters = [] \n",
    "        for tmp_index in range(nb_classes): \n",
    "            counters.append(len(zero_grasps_list[tmp_index]))\n",
    "            \n",
    "        enough_samples = True \n",
    "        for tmp_index in range(nb_classes): \n",
    "            if counters[tmp_index] < nb_tot_samp_class:\n",
    "                # not enough samples \n",
    "                enough_samples = False \n",
    "        if enough_samples: \n",
    "            break \n",
    "        \n",
    "        for metric_index in range(len(file_metrics)):\n",
    "            if file_metrics[metric_index, 0] == 1.0 and file_metrics[metric_index,1] < lim:\n",
    "                curr_class = int(file_obj_classes[metric_index,0])\n",
    "                tmp_list = [] \n",
    "                \n",
    "                tmp_list.append((file_metrics[metric_index,1] - gripper_min) / (gripper_max - gripper_min))\n",
    "                tmp_hand_info = file_hand_info[metric_index]\n",
    "                tmp_hand_info[0] = (tmp_hand_info[0] - x_min) / (x_max - x_min)\n",
    "                tmp_hand_info[1] = (tmp_hand_info[1] - y_min) / (y_max - y_min)\n",
    "                tmp_hand_info[2] = (tmp_hand_info[2] - z_min) / (z_max - z_min)\n",
    "                \n",
    "                for tmp_index in range(13): \n",
    "                    tmp_list.append(tmp_hand_info[tmp_index])\n",
    "                \n",
    "                zero_grasps_list[curr_class].append(tmp_list.copy())\n",
    "                \n",
    "    return zero_grasps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ff0219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_class_buckets(non_zero_grasps_list, zero_grasps_list, nb_tot_samp_class, nb_classes):\n",
    "    equalized_grasps = non_zero_grasps_list.copy()\n",
    "    for class_index in range(nb_classes): \n",
    "        curr_len = len(non_zero_grasps_list[class_index])\n",
    "        samp_to_complete = nb_tot_samp_class - curr_len\n",
    "        # Clip, if necessary \n",
    "        if samp_to_complete < 0: \n",
    "            equalized_grasps[class_index] = equalized_grasps[class_index][:nb_tot_samp_class]\n",
    "        else: \n",
    "            for samp_index in range(samp_to_complete): \n",
    "                equalized_grasps[class_index].append(zero_grasps_list[class_index][samp_index])\n",
    "    # Shuffle the data per class \n",
    "    for class_index in range(nb_classes): \n",
    "        random.shuffle(equalized_grasps[class_index])\n",
    "    return equalized_grasps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f262abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_total_YCB_eq_data_seq(data_set_loc_str, nb_samples, nb_classes, joint_dist_lim, seq_len, nb_tot_samp_class, test_train_ratio, rand_seed, verbose): \n",
    "    if verbose >= 1:\n",
    "        print(\"Loading Data.\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    non_zero_grasps_list = load_non_zero_fused_grasps(data_set_loc_str, nb_classes, joint_dist_lim)\n",
    "    zero_grasps_list = load_zero_fused_grasps_buckets(data_set_loc_str, nb_classes, joint_dist_lim, nb_tot_samp_class)\n",
    "    equalized_grasps = equalize_class_buckets(non_zero_grasps_list, zero_grasps_list, nb_tot_samp_class, nb_classes)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    if verbose >= 1:\n",
    "        print(\"Time taken to load data: \", end_time - start_time)\n",
    "        \n",
    "    inputs = [] \n",
    "    outputs = []\n",
    "    \n",
    "    # Parsing all buckets \n",
    "    for bucket_index in range(nb_classes):\n",
    "        bucket_offset = 0 \n",
    "        while (bucket_offset + seq_len - 1  < len(non_zero_metrics_list[bucket_index])):\n",
    "            # Build the sequence \n",
    "            tmp_buffer = [] \n",
    "            for seq_index in range(seq_len): \n",
    "                # Fusing the data \n",
    "                tmp_buffer.append(equalized_grasps[bucket_index][bucket_offset + seq_index].copy())\n",
    "            \n",
    "            inputs.append(tmp_buffer.copy())\n",
    "            outputs.append(tf.one_hot(bucket_index, nb_classes, dtype=np.float64).numpy().tolist())\n",
    "            bucket_offset += seq_len \n",
    "            \n",
    "        \n",
    "    # Shuffling the data \n",
    "    X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=test_train_ratio, random_state=rand_seed)\n",
    "    \n",
    "    if verbose >= 1:\n",
    "        print(\"Size of Train set: \", len(X_train))\n",
    "        print(\"Size of Test set: \", len(X_test))\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76478228",
   "metadata": {},
   "source": [
    "Test codes for equalizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ea0ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_metrics_list, non_zero_hands_list = load_non_zero_grasps(data_set_loc_str, nb_samples, nb_classes, joint_dist_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1593bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_grasps_list = load_non_zero_fused_grasps(data_set_loc_str, nb_classes, joint_dist_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05488bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_grasps_list = load_zero_fused_grasps_buckets(data_set_loc_str, nb_classes, joint_dist_lim, nb_tot_samp_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d48b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized_grasps = equalize_class_buckets(non_zero_grasps_list, zero_grasps_list, nb_tot_samp_class, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1a4269cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data.\n",
      "Time taken to load data:  55.12330365180969\n",
      "Size of Train set:  7800\n",
      "Size of Test set:  1951\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_total_YCB_eq_data_seq(data_set_loc_str, nb_samples, nb_classes, joint_dist_lim, seq_len, nb_tot_samp_class, test_train_ratio, rand_seed, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f63103b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34534918164373724, 0.4333641429742177, 0.39342081050078076, 0.5504633675922047, 0.0, -0.7448044419288635, 0.6672828793525696, 0.0, 0.6672828793525696, 0.7448044419288635, -1.0, 0.0, -4.371139183945161e-08, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(equalized_grasps[1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7502dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(equalized_grasps[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc152f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "counters = [] \n",
    "for class_index in range(nb_classes): \n",
    "    counters.append(len(equalized_grasps[class_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "084c1d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(counters)\n",
    "print(max(counters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "062e8520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0017974316897477844, 0.16824208696683246, 0.6753605902194977, 0.07357561317357149, 0.0, 0.3725760877132416, -0.9280017018318176, 0.0, -0.9280017018318176, -0.3725760877132416, -1.0, 0.0, -4.371138828673793e-08, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(zero_grasps_list[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b58e57f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20005\n"
     ]
    }
   ],
   "source": [
    "print(len(zero_grasps_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb16e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "counters = [] \n",
    "for class_index in range(nb_classes): \n",
    "    counters.append(len(zero_grasps_list[class_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "285dbfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20005, 28294, 29189, 31977, 33734, 34323, 33175, 33848, 33253, 34078, 26529, 30754, 31736, 32530, 32390, 33226]\n",
      "34323\n"
     ]
    }
   ],
   "source": [
    "print(counters)\n",
    "print(max(counters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66706e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "print(len(non_zero_grasps_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e705668",
   "metadata": {},
   "outputs": [],
   "source": [
    "counters = [] \n",
    "for class_index in range(nb_classes): \n",
    "    counters.append(len(non_zero_grasps_list[class_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e09542ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2223, 3496, 4480, 2495, 3518, 2802, 1863, 2173, 2197, 2423, 1586, 15780, 10946, 4795, 4800, 8012]\n",
      "15780\n"
     ]
    }
   ],
   "source": [
    "print(counters)\n",
    "print(max(counters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cf10826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15780\n"
     ]
    }
   ],
   "source": [
    "tmp_test_list = non_zero_grasps_list[11]\n",
    "print(len(tmp_test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81305b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "tmp_test_list = tmp_test_list[:10000]\n",
    "print(len(tmp_test_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
